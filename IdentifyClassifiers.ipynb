{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a68c5d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row-Column Count before cleaning: ( 235795  ,  57 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "1        134850\n",
       "0        100945\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*****************************************Import********************************************\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "df=pd.read_csv(\"dataset/PhishingDataset.csv\")\n",
    "\n",
    "ROWS = len(df.axes[0]) \n",
    "COLUMNS = len(df.axes[1])\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df=df.dropna()\n",
    "LABEL = df.iloc[:,-1:].columns[0]\n",
    "print(\"Row-Column Count before cleaning: (\", ROWS , \" , \",  COLUMNS , \")\")\n",
    "\n",
    "df.iloc[:,-1:].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddacaad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Train-Test Split.\n"
     ]
    }
   ],
   "source": [
    "cols = df.select_dtypes(include=['float64','int64']).columns\n",
    "cols=cols.drop('URLSimilarityIndex')\n",
    "df = pd.DataFrame(df[cols]).copy()\n",
    "df = df.reset_index(drop=True)\n",
    "LABEL = df.iloc[:,-1:].columns[0]\n",
    "\n",
    "Train, Test=train_test_split(df,test_size=0.3, random_state=4)\n",
    "\n",
    "yTrain = pd.DataFrame(Train[LABEL]).copy()\n",
    "yTest = pd.DataFrame(Test[LABEL]).copy()\n",
    "\n",
    "Train.drop(LABEL, axis=1, inplace=True)\n",
    "Test.drop(LABEL, axis=1, inplace=True)\n",
    "\n",
    "xTrain = pd.DataFrame(Train).copy()\n",
    "xTest = pd.DataFrame(Test).copy()\n",
    "print(\"Finished Train-Test Split.\")\n",
    "PERFORMANCE = pd.DataFrame(columns=['Model','Accuracy','Precision','Recall','F1Score','TrainingTime','PredictionTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88cb1b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianNB_Training', 'Accuracy': 0.5720482745250097, 'Precision': 0.5720482745250097, 'Recall': 1.0, 'F1Score': 0.7277744377129292, 'TrainingTime': 140, 'PredictionTime': 0}\n",
      "{'Model': 'GaussianNB_Prediction', 'Accuracy': 0.571537624224261, 'Precision': 0.571537624224261, 'Recall': 1.0, 'F1Score': 0.7273610448956095, 'TrainingTime': 140, 'PredictionTime': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "start = time.time()\n",
    "n = len(yTrain.axes[0])\n",
    "for i in range(0,n):\n",
    "    try:\n",
    "        X = xTrain.iloc[[i]].to_numpy() \n",
    "        Y = yTrain.iloc[[i]]\n",
    "        Y = np.array(Y[LABEL])\n",
    "        model.partial_fit(X, Y, classes=[0,1])        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "end = time.time()\n",
    "trainTime = int(end - start)\n",
    "\n",
    "start = time.time()\n",
    "X = xTrain.to_numpy()\n",
    "Y = np.array(yTrain[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "trainRow = {'Model':\"GaussianNB_Training\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "start = time.time()\n",
    "X = xTest.to_numpy()\n",
    "Y = np.array(yTest[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "testRow = {'Model':\"GaussianNB_Prediction\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "print(trainRow)\n",
    "print(testRow)\n",
    "PERFORMANCE = PERFORMANCE.append(trainRow , ignore_index=True)\n",
    "PERFORMANCE = PERFORMANCE.append(testRow , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acaeb14b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MultinomialNB_Training', 'Accuracy': 0.6893660333462582, 'Precision': 0.6528531549786739, 'Recall': 0.9759055284897268, 'F1Score': 0.7823418038563096, 'TrainingTime': 212, 'PredictionTime': 0}\n",
      "{'Model': 'MultinomialNB_Prediction', 'Accuracy': 0.6908494606935354, 'Precision': 0.6537041024197154, 'Recall': 0.9762552559980213, 'F1Score': 0.7830650041166959, 'TrainingTime': 212, 'PredictionTime': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "\n",
    "start = time.time()\n",
    "n = len(yTrain.axes[0])\n",
    "for i in range(0,n):\n",
    "    try:\n",
    "        X = xTrain.iloc[[i]].to_numpy() \n",
    "        Y = yTrain.iloc[[i]]\n",
    "        Y = np.array(Y[LABEL])\n",
    "        model.partial_fit(X, Y, classes=[0,1])        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "end = time.time()\n",
    "trainTime = int(end - start)\n",
    "\n",
    "start = time.time()\n",
    "X = xTrain.to_numpy()\n",
    "Y = np.array(yTrain[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "trainRow = {'Model':\"MultinomialNB_Training\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "start = time.time()\n",
    "X = xTest.to_numpy()\n",
    "Y = np.array(yTest[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "testRow = {'Model':\"MultinomialNB_Prediction\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "print(trainRow)\n",
    "print(testRow)\n",
    "PERFORMANCE = PERFORMANCE.append(trainRow , ignore_index=True)\n",
    "PERFORMANCE = PERFORMANCE.append(testRow , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd781b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BernoulliNB_Training', 'Accuracy': 0.986768127181078, 'Precision': 0.9792177563489755, 'Recall': 0.9980512603262021, 'F1Score': 0.9885448136958712, 'TrainingTime': 158, 'PredictionTime': 0}\n",
      "{'Model': 'BernoulliNB_Prediction', 'Accuracy': 0.9865420772134184, 'Precision': 0.9787533349502789, 'Recall': 0.99812020776651, 'F1Score': 0.9883419054616703, 'TrainingTime': 158, 'PredictionTime': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "\n",
    "start = time.time()\n",
    "n = len(yTrain.axes[0])\n",
    "for i in range(0,n):\n",
    "    try:\n",
    "        X = xTrain.iloc[[i]].to_numpy() \n",
    "        Y = yTrain.iloc[[i]]\n",
    "        Y = np.array(Y[LABEL])\n",
    "        model.partial_fit(X, Y, classes=[0,1])        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "end = time.time()\n",
    "trainTime = int(end - start)\n",
    "\n",
    "start = time.time()\n",
    "X = xTrain.to_numpy()\n",
    "Y = np.array(yTrain[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "trainRow = {'Model':\"BernoulliNB_Training\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "start = time.time()\n",
    "X = xTest.to_numpy()\n",
    "Y = np.array(yTest[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "testRow = {'Model':\"BernoulliNB_Prediction\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "print(trainRow)\n",
    "print(testRow)\n",
    "PERFORMANCE = PERFORMANCE.append(trainRow , ignore_index=True)\n",
    "PERFORMANCE = PERFORMANCE.append(testRow , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52516162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PassiveAggressive_Training', 'Accuracy': 0.9939535672741373, 'Precision': 0.9938364274537996, 'Recall': 0.9956047447574666, 'F1Score': 0.9947198002200964, 'TrainingTime': 108, 'PredictionTime': 0}\n",
      "{'Model': 'PassiveAggressive_Prediction', 'Accuracy': 0.9941757729116895, 'Precision': 0.9942446398577216, 'Recall': 0.9955725946079644, 'F1Score': 0.9949081741107844, 'TrainingTime': 108, 'PredictionTime': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "model = PassiveAggressiveClassifier()\n",
    "\n",
    "start = time.time()\n",
    "n = len(yTrain.axes[0])\n",
    "for i in range(0,n):\n",
    "    try:\n",
    "        X = xTrain.iloc[[i]].to_numpy() \n",
    "        Y = yTrain.iloc[[i]]\n",
    "        Y = np.array(Y[LABEL])\n",
    "        model.partial_fit(X, Y, classes=[0,1])        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "end = time.time()\n",
    "trainTime = int(end - start)\n",
    "\n",
    "start = time.time()\n",
    "X = xTrain.to_numpy()\n",
    "Y = np.array(yTrain[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "trainRow = {'Model':\"PassiveAggressive_Training\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "start = time.time()\n",
    "X = xTest.to_numpy()\n",
    "Y = np.array(yTest[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "testRow = {'Model':\"PassiveAggressive_Prediction\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "print(trainRow)\n",
    "print(testRow)\n",
    "PERFORMANCE = PERFORMANCE.append(trainRow , ignore_index=True)\n",
    "PERFORMANCE = PERFORMANCE.append(testRow , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b67bde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Perceptron_Training', 'Accuracy': 0.9415592283830942, 'Precision': 0.9084785290262894, 'Recall': 0.9984219445032833, 'F1Score': 0.9513290411124792, 'TrainingTime': 135, 'PredictionTime': 0}\n",
      "{'Model': 'Perceptron_Prediction', 'Accuracy': 0.9436378800944316, 'Precision': 0.9112184333461217, 'Recall': 0.9986890922582241, 'F1Score': 0.9529507558324778, 'TrainingTime': 135, 'PredictionTime': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "model = Perceptron()\n",
    "\n",
    "start = time.time()\n",
    "n = len(yTrain.axes[0])\n",
    "for i in range(0,n):\n",
    "    try:\n",
    "        X = xTrain.iloc[[i]].to_numpy() \n",
    "        Y = yTrain.iloc[[i]]\n",
    "        Y = np.array(Y[LABEL])\n",
    "        model.partial_fit(X, Y, classes=[0,1])        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "end = time.time()\n",
    "trainTime = int(end - start)\n",
    "\n",
    "start = time.time()\n",
    "X = xTrain.to_numpy()\n",
    "Y = np.array(yTrain[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "trainRow = {'Model':\"Perceptron_Training\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "start = time.time()\n",
    "X = xTest.to_numpy()\n",
    "Y = np.array(yTest[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "testRow = {'Model':\"Perceptron_Prediction\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "print(trainRow)\n",
    "print(testRow)\n",
    "PERFORMANCE = PERFORMANCE.append(trainRow , ignore_index=True)\n",
    "PERFORMANCE = PERFORMANCE.append(testRow , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af438f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SGDClassifier_Training', 'Accuracy': 0.944327985653354, 'Precision': 0.913169095333663, 'Recall': 0.9975323024782885, 'F1Score': 0.9534882543796157, 'TrainingTime': 108, 'PredictionTime': 0}\n",
      "{'Model': 'SGDClassifier_Prediction', 'Accuracy': 0.9465782665856175, 'Precision': 0.9160442254864123, 'Recall': 0.9979965372248331, 'F1Score': 0.9552659303715805, 'TrainingTime': 108, 'PredictionTime': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier()\n",
    "\n",
    "start = time.time()\n",
    "n = len(yTrain.axes[0])\n",
    "for i in range(0,n):\n",
    "    try:\n",
    "        X = xTrain.iloc[[i]].to_numpy() \n",
    "        Y = yTrain.iloc[[i]]\n",
    "        Y = np.array(Y[LABEL])\n",
    "        model.partial_fit(X, Y, classes=[0,1])        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "end = time.time()\n",
    "trainTime = int(end - start)\n",
    "\n",
    "start = time.time()\n",
    "X = xTrain.to_numpy()\n",
    "Y = np.array(yTrain[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "trainRow = {'Model':\"SGDClassifier_Training\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "start = time.time()\n",
    "X = xTest.to_numpy()\n",
    "Y = np.array(yTest[LABEL])\n",
    "predict = model.predict(X)\n",
    "accuracy = metrics.accuracy_score(Y, predict)\n",
    "precision = metrics.precision_score(Y, predict)\n",
    "recall = metrics.recall_score(Y, predict)\n",
    "f1score = metrics.f1_score(Y, predict, zero_division=1)\n",
    "end = time.time()\n",
    "predictionTime = int(end - start)\n",
    "testRow = {'Model':\"SGDClassifier_Prediction\",'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1Score':f1score,\n",
    "           'TrainingTime':trainTime,'PredictionTime':predictionTime}\n",
    "\n",
    "print(trainRow)\n",
    "print(testRow)\n",
    "PERFORMANCE = PERFORMANCE.append(trainRow , ignore_index=True)\n",
    "PERFORMANCE = PERFORMANCE.append(testRow , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b140f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1Score</th>\n",
       "      <th>TrainingTime</th>\n",
       "      <th>PredictionTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB_Training</td>\n",
       "      <td>0.572048</td>\n",
       "      <td>0.572048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727774</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB_Prediction</td>\n",
       "      <td>0.571538</td>\n",
       "      <td>0.571538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727361</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB_Training</td>\n",
       "      <td>0.689366</td>\n",
       "      <td>0.652853</td>\n",
       "      <td>0.975906</td>\n",
       "      <td>0.782342</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB_Prediction</td>\n",
       "      <td>0.690849</td>\n",
       "      <td>0.653704</td>\n",
       "      <td>0.976255</td>\n",
       "      <td>0.783065</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BernoulliNB_Training</td>\n",
       "      <td>0.986768</td>\n",
       "      <td>0.979218</td>\n",
       "      <td>0.998051</td>\n",
       "      <td>0.988545</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BernoulliNB_Prediction</td>\n",
       "      <td>0.986542</td>\n",
       "      <td>0.978753</td>\n",
       "      <td>0.998120</td>\n",
       "      <td>0.988342</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PassiveAggressive_Training</td>\n",
       "      <td>0.993954</td>\n",
       "      <td>0.993836</td>\n",
       "      <td>0.995605</td>\n",
       "      <td>0.994720</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressive_Prediction</td>\n",
       "      <td>0.994176</td>\n",
       "      <td>0.994245</td>\n",
       "      <td>0.995573</td>\n",
       "      <td>0.994908</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Perceptron_Training</td>\n",
       "      <td>0.941559</td>\n",
       "      <td>0.908479</td>\n",
       "      <td>0.998422</td>\n",
       "      <td>0.951329</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Perceptron_Prediction</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>0.911218</td>\n",
       "      <td>0.998689</td>\n",
       "      <td>0.952951</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SGDClassifier_Training</td>\n",
       "      <td>0.944328</td>\n",
       "      <td>0.913169</td>\n",
       "      <td>0.997532</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SGDClassifier_Prediction</td>\n",
       "      <td>0.946578</td>\n",
       "      <td>0.916044</td>\n",
       "      <td>0.997997</td>\n",
       "      <td>0.955266</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Accuracy  Precision    Recall   F1Score  \\\n",
       "0            GaussianNB_Training  0.572048   0.572048  1.000000  0.727774   \n",
       "1          GaussianNB_Prediction  0.571538   0.571538  1.000000  0.727361   \n",
       "2         MultinomialNB_Training  0.689366   0.652853  0.975906  0.782342   \n",
       "3       MultinomialNB_Prediction  0.690849   0.653704  0.976255  0.783065   \n",
       "4           BernoulliNB_Training  0.986768   0.979218  0.998051  0.988545   \n",
       "5         BernoulliNB_Prediction  0.986542   0.978753  0.998120  0.988342   \n",
       "6     PassiveAggressive_Training  0.993954   0.993836  0.995605  0.994720   \n",
       "7   PassiveAggressive_Prediction  0.994176   0.994245  0.995573  0.994908   \n",
       "8            Perceptron_Training  0.941559   0.908479  0.998422  0.951329   \n",
       "9          Perceptron_Prediction  0.943638   0.911218  0.998689  0.952951   \n",
       "10        SGDClassifier_Training  0.944328   0.913169  0.997532  0.953488   \n",
       "11      SGDClassifier_Prediction  0.946578   0.916044  0.997997  0.955266   \n",
       "\n",
       "   TrainingTime PredictionTime  \n",
       "0           140              0  \n",
       "1           140              0  \n",
       "2           212              0  \n",
       "3           212              0  \n",
       "4           158              0  \n",
       "5           158              0  \n",
       "6           108              0  \n",
       "7           108              0  \n",
       "8           135              0  \n",
       "9           135              0  \n",
       "10          108              0  \n",
       "11          108              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERFORMANCE.to_csv('dataset/ReportsMay19/P7_IdentifyClassifiersReport.csv',index = False)\n",
    "PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4145205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
